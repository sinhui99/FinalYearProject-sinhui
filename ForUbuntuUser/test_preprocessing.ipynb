{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2     # for capturing videos\n",
    "import os \n",
    "import shutil\n",
    "import math   # for mathematical operations\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing import image   # for preprocessing the images\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16379497450660707184\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7347613216\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6892062830417803198\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:0a:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7596800736\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11252568984326227376\n",
      "physical_device_desc: \"device: 1, name: GeForce RTX 2080 SUPER, pci bus id: 0000:0b:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    if tf.test.gpu_device_name():\n",
    "        print(\"GPU\")\n",
    "    else:\n",
    "        print(\"no GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_video_frame_num(video_name):  \n",
    "    cap = cv2.VideoCapture(video_name)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_suspense_frame(length,j,k,sus_frame):\n",
    "    if k == len(sus_frame[j]) - 1:\n",
    "        non_sus_start_frame = sus_frame[j][k][1] + 1\n",
    "        non_sus_end_frame = length[j]\n",
    "    else:\n",
    "        non_sus_start_frame = sus_frame[j][k][1] + 1\n",
    "        non_sus_end_frame = sus_frame[j][k+1][0] - 1\n",
    "    return non_sus_start_frame, non_sus_end_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_file(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    temp = f.read()\n",
    "    video_path = temp.split('\\n')\n",
    "    \n",
    "    pd_sus = pd.DataFrame()\n",
    "    pd_sus['video_path'] = video_path\n",
    "    pd_sus = pd_sus[:]\n",
    "    \n",
    "    video_name = []\n",
    "    s_label = []\n",
    "    ns_label = []\n",
    "    for i in range(pd_sus.shape[0]):\n",
    "        video_name.append(pd_sus['video_path'][i].split('/')[1])\n",
    "        s_label.append(\"suspense\")\n",
    "        ns_label.append(\"non-suspense\")\n",
    "        \n",
    "    pd_sus['video_name'] = video_name\n",
    "    pd_non_sus = pd_sus.copy()\n",
    "    \n",
    "    pd_sus['label'] = s_label\n",
    "    pd_non_sus['label'] = ns_label\n",
    "    \n",
    "    video_rnn = pd.DataFrame(pd_sus.sort_values(by = \"video_name\"))\n",
    "    video_rnn = video_rnn.reset_index(drop = True)\n",
    "    \n",
    "    return pd_sus, pd_non_sus, video_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_start_end_frame(txtfilefolder, videofolder, pd_sus, pd_non_sus):\n",
    "    # open the .txt file which have suspense label\n",
    "    sus_frame = []\n",
    "    video_text_file = []\n",
    "    total_frame_per_video = []\n",
    "    for i in range(pd_sus.video_name.shape[0]):\n",
    "        if(\"mkv\" in pd_sus.video_name[i]):\n",
    "            video_text_file.append(pd_sus.video_name[i].replace(\"mkv\", \"txt\"))\n",
    "        elif (\"mp4\" in pd_sus.video_name[i]):\n",
    "            video_text_file.append(pd_sus.video_name[i].replace(\"mp4\", \"txt\"))\n",
    "        else:\n",
    "            video_text_file.append(pd_sus.video_name[i].replace(\"webm\", \"txt\"))\n",
    "        f = open(txtfilefolder + video_text_file[i], \"rt\")\n",
    "        sus_frame.append([[int(token) for token in line.split()] for line in f.readlines()[::]])\n",
    "        total_frame_per_video.append(count_video_frame_num(videofolder + pd_sus.video_name[i]))\n",
    "        \n",
    "    sus_start_frame = []\n",
    "    sus_end_frame = []\n",
    "    non_sus_start_frame = []\n",
    "    non_sus_end_frame = []\n",
    "    non_sus_start_frame_each = []\n",
    "    non_sus_end_frame_each = []\n",
    "    sus_scene_per_video = []\n",
    "    non_sus_scene_per_video = []\n",
    "    \n",
    "    for j in range(len(sus_frame)):\n",
    "        non_sus_scene_count = 0\n",
    "        sus_scene_per_video.append(len(sus_frame[j]))\n",
    "        for k in range(len(sus_frame[j])):\n",
    "            if k == 0 and sus_frame[j][k][0] != 0:\n",
    "                non_sus_start_frame.append(0)\n",
    "                non_sus_end_frame.append(sus_frame[j][k][0] - 1)\n",
    "                non_sus_scene_count += 1\n",
    "            non_sus_start_frame_each, non_sus_end_frame_each = exclude_suspense_frame(total_frame_per_video,j,k,sus_frame)\n",
    "            sus_start_frame.append(sus_frame[j][k][0])\n",
    "            sus_end_frame.append(sus_frame[j][k][1])\n",
    "            non_sus_start_frame.append(non_sus_start_frame_each)\n",
    "            non_sus_end_frame.append(non_sus_end_frame_each)\n",
    "            non_sus_scene_count += 1\n",
    "        if non_sus_scene_count == 0:\n",
    "            non_sus_start_frame.append(0)\n",
    "            non_sus_end_frame.append(count_video_frame_num(videofolder + pd_sus.video_name[j]))\n",
    "            non_sus_scene_per_video.append(1)\n",
    "        else:\n",
    "            non_sus_scene_per_video.append(non_sus_scene_count)\n",
    "    \n",
    "    pd_sus['scene_per_video'] = sus_scene_per_video\n",
    "    pd_non_sus['scene_per_video'] = non_sus_scene_per_video\n",
    "    pd_sus = pd_sus.loc[pd_sus.index.repeat(pd_sus.scene_per_video)].reset_index(drop=True)\n",
    "    pd_non_sus = pd_non_sus.loc[pd_non_sus.index.repeat(pd_non_sus.scene_per_video)].reset_index(drop=True)\n",
    "    pd_sus['start_frame'] = sus_start_frame\n",
    "    pd_sus['end_frame'] = sus_end_frame\n",
    "    pd_non_sus['start_frame'] = non_sus_start_frame\n",
    "    pd_non_sus['end_frame'] = non_sus_end_frame\n",
    "    data = pd.concat([pd_sus, pd_non_sus], ignore_index=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(path, data):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    \n",
    "    # storing the frames from training videos\n",
    "    for i in tqdm(range(data.shape[0])):\n",
    "        count = 0\n",
    "        currentframe = 0\n",
    "        # Read the video from specified path \n",
    "        cam = cv2.VideoCapture(data.video_path[i]) \n",
    "        frameRate = cam.get(5) #frame rate\n",
    "        \n",
    "        try: \n",
    "            # creating a folder named data \n",
    "            if not os.path.exists(path): \n",
    "                os.makedirs(path) \n",
    "        \n",
    "        # if not created then raise error \n",
    "        except OSError: \n",
    "            print ('Error: Creating directory of data') \n",
    "            \n",
    "        # frame \n",
    "        currentframe = data.start_frame[i]\n",
    "        cam.set(1, currentframe)\n",
    "        while(currentframe <= data.end_frame[i]): \n",
    "            \n",
    "            # reading from frame\n",
    "            ret,frame = cam.read()\n",
    "            \n",
    "            if (ret != True):\n",
    "                break\n",
    "                \n",
    "            if math.floor(currentframe) % math.floor(frameRate) == 0:\n",
    "                if(\"mkv\" in data.video_name[i]):\n",
    "                    name = path + '/' + data.label[i] + '_' + data.video_name[i].replace(\".mkv\", \"_\") + str(currentframe) + '.jpg'\n",
    "                elif(\"mp4\" in data.video_name[i]):\n",
    "                    name = path + '/' + data.label[i] + '_' + data.video_name[i].replace(\".mp4\", \"_\") + str(currentframe) + '.jpg'\n",
    "                else:\n",
    "                    name = path + '/' + data.label[i] + '_' + data.video_name[i].replace(\".webm\", \"_\") + str(currentframe) + '.jpg'\n",
    "                cv2.imwrite(name, frame)\n",
    "                \n",
    "            currentframe += 1\n",
    "        \n",
    "        # Release all space and windows once done \n",
    "        cam.release() \n",
    "        cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_index(df_data):\n",
    "    index = []\n",
    "    for i in range(len(df_data)):\n",
    "        if \"_\" in df_data.iloc[i,2]:\n",
    "            index.append(df_data.iloc[i, 0].split('_')[3].split('.')[0])\n",
    "        else:\n",
    "            index.append(df_data.iloc[i, 0].split('_')[2].split('.')[0])\n",
    "    index = [int(i) for i in index]\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_each_video_frame(df_data):\n",
    "    video = df_data.iloc[0,2]\n",
    "    each_video_frame = []\n",
    "    each_video_extra_frame = []\n",
    "    ct = 0\n",
    "    suspense = 0\n",
    "    non_suspense = 0\n",
    "    for i in range(df_data.shape[0]):\n",
    "        ct += 1\n",
    "        if df_data.iloc[i, 1] == 1:\n",
    "            suspense += 1\n",
    "        else:\n",
    "            non_suspense += 1\n",
    "        if video != df_data.iloc[i, 2]:\n",
    "            each_video_frame.append(ct - 1)\n",
    "            if df_data.iloc[i, 1] == 1:\n",
    "                each_video_extra_frame.append(non_suspense - (suspense - 1))\n",
    "                suspense = 1\n",
    "                non_suspense = 0\n",
    "            else:\n",
    "                each_video_extra_frame.append((non_suspense - 1) - suspense)\n",
    "                suspense = 0\n",
    "                non_suspense = 1\n",
    "            \n",
    "            video = df_data.iloc[i, 2]    \n",
    "            ct = 1\n",
    "        if i == (df_data.shape[0] -1):\n",
    "            each_video_frame.append(ct)\n",
    "            each_video_extra_frame.append(non_suspense -  suspense)\n",
    "    return each_video_frame, each_video_extra_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frame_to_csv(path, csv_name):\n",
    "    # getting the names of all the images\n",
    "    images = glob(path + \"/*.jpg\")\n",
    "    list_image = []\n",
    "    list_class = []\n",
    "    list_video_name = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        # creating the image name\n",
    "        list_image.append(images[i].split('/')[1])\n",
    "        # creating the class of image\n",
    "        if (images[i].split('/')[1].split('_')[0] == 'non-suspense'):\n",
    "            list_class.append(0)\n",
    "        else:\n",
    "            list_class.append(1)\n",
    "        if \"XLWx0_I1qLQ\" in images[i].split('/')[1] or \"_y3rFsvz8qQ\" in images[i].split('/')[1]:\n",
    "            temp = \"_\".join(images[i].split('/')[1].split('_')[1:3])\n",
    "            list_video_name.append(temp)\n",
    "        else:\n",
    "            list_video_name.append(images[i].split('/')[1].split('_')[1])\n",
    "        \n",
    "    # storing the images and their class in a dataframe\n",
    "    df_data = pd.DataFrame()\n",
    "    df_data['image'] = list_image\n",
    "    df_data['class'] = list_class\n",
    "    df_data['video'] = list_video_name\n",
    "    df_data['index'] = calculate_index(df_data)\n",
    "    \n",
    "    df_data = df_data.sort_values(by = ['video', 'index'], ascending = True)\n",
    "    \n",
    "    each_video_frame, each_video_extra_frame = cal_each_video_frame(df_data)\n",
    "    \n",
    "    df_data = df_data.reset_index(drop = True)\n",
    "    df_data = df_data.drop(['index'], axis = 1)\n",
    "    df_data = df_data.drop(['video'], axis = 1)\n",
    "    df_data.to_csv(csv_name,header=True, index=False)\n",
    "    \n",
    "    return each_video_frame, each_video_extra_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_array(path, df_csv):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        if tf.test.gpu_device_name():\n",
    "            print(\"Using GPU\")\n",
    "        base_model = tf.keras.applications.ResNet50(weights='imagenet', pooling='avg', include_top = False) \n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        list_image = []\n",
    "    \n",
    "        # for loop to read and store frames\n",
    "        for i in tqdm(range(df_csv.shape[0])):\n",
    "            # loading the image and keeping the target size as (224,224,3)\n",
    "            img = image.load_img(path + df_csv['image'][i], target_size=(224,224,3))\n",
    "            # converting it to array\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            features = base_model.predict(x)\n",
    "            features = features.squeeze()\n",
    "\n",
    "            list_image.append(features)\n",
    "\n",
    "        X = np.array(list_image)\n",
    "        y = df_csv['class']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_for_loop_no(each_video_frame, each_video_extra_frame):\n",
    "    each_video_frame = [int(i) for i in each_video_frame]\n",
    "    each_video_extra_frame = [int(i) for i in each_video_extra_frame]\n",
    "    each_video_frame = np.array(each_video_frame, dtype=float)\n",
    "    each_video_extra_frame = np.array(each_video_extra_frame)\n",
    "    sus_count = (each_video_frame - each_video_extra_frame) / 2\n",
    "    for_loop_num = np.divide(each_video_extra_frame, sus_count, out=np.zeros_like(each_video_frame), where=sus_count!=0)\n",
    "    return (np.floor(for_loop_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_rnn_shape(each_video_frame, video_rnn, X, y, option, n):\n",
    "    each_video_frame = [int(i) for i in each_video_frame]\n",
    "    \n",
    "    X_rnn = []\n",
    "    y_rnn = []\n",
    "    frame_count = 0\n",
    "    j = 0\n",
    "    for i in range(video_rnn.shape[0]):\n",
    "        rnn_end_frame = each_video_frame[i]\n",
    "        loop_count = n[i].astype(np.int8)\n",
    "        print(\"video \", i , \" last frame of video \", rnn_end_frame)\n",
    "        for k in range(20, rnn_end_frame):\n",
    "            if y[k + frame_count] == 1:\n",
    "                if(option == \"train\"):\n",
    "                    for m in range(loop_count):\n",
    "                        original = X[frame_count + j:frame_count + k, :]\n",
    "                        noise = np.random.normal(0, .0001, original.shape)\n",
    "                        new =  np.float32(original + noise)\n",
    "                        X_rnn.append(new)\n",
    "                        y_rnn.append(y[k + frame_count])\n",
    "                X_rnn.append(X[frame_count + j:frame_count + k, :])\n",
    "                y_rnn.append(y[k + frame_count])\n",
    "                j+=1\n",
    "            else:\n",
    "                X_rnn.append(X[frame_count + j:frame_count + k, :])\n",
    "                y_rnn.append(y[k + frame_count])\n",
    "                j+=1\n",
    "        frame_count += each_video_frame[i]\n",
    "        print(\"total frames processed: \", frame_count)\n",
    "        j=0\n",
    "    \n",
    "    X_rnn, y_rnn = np.array(X_rnn), np.array(y_rnn)\n",
    "\n",
    "    return X_rnn, y_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [27:31<00:00,  9.55s/it]\n",
      "100%|██████████| 34404/34404 [00:00<00:00, 649222.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34404/34404 [24:44<00:00, 23.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video  0  last frame of video  1500\n",
      "total frames processed:  1500\n",
      "video  1  last frame of video  1475\n",
      "total frames processed:  2975\n",
      "video  2  last frame of video  2775\n",
      "total frames processed:  5750\n",
      "video  3  last frame of video  2539\n",
      "total frames processed:  8289\n",
      "video  4  last frame of video  5369\n",
      "total frames processed:  13658\n",
      "video  5  last frame of video  6847\n",
      "total frames processed:  20505\n",
      "video  6  last frame of video  7663\n",
      "total frames processed:  28168\n",
      "video  7  last frame of video  1396\n",
      "total frames processed:  29564\n",
      "video  8  last frame of video  4840\n",
      "total frames processed:  34404\n"
     ]
    }
   ],
   "source": [
    "pd_sus, pd_non_sus, video_rnn = read_txt_file(\"testlist01.txt\")\n",
    "test = cal_start_end_frame(\"testfiles/\", \"testvideos/\", pd_sus, pd_non_sus)\n",
    "\n",
    "extract_frames('testdata', test)\n",
    "\n",
    "each_video_frame, each_video_extra_frame = save_frame_to_csv('testdata', 'test_new.csv')\n",
    "n = calculate_for_loop_no(each_video_frame, each_video_extra_frame)\n",
    "\n",
    "test = pd.read_csv('test_new.csv')\n",
    "X, y = img_to_array('testdata/', test)\n",
    "X_testing, y_testing = transform_to_rnn_shape(each_video_frame, video_rnn, X, y, \"test\", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/X_testing.pickle', 'wb') as f:\n",
    "    pickle.dump(X_testing, f)\n",
    "    \n",
    "with open('pickle/y_testing.pickle', 'wb') as f:\n",
    "    pickle.dump(y_testing, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
